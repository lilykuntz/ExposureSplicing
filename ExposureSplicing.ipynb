{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS 452 Final Code: Exposure Splicing\n",
    "# Lily Kuntz, Lucy Pappas, Ali Scannell\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import skimage.io as skio\n",
    "import skimage.color as skc\n",
    "import skimage.morphology as skm\n",
    "import skimage.measure as skme\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as sknf\n",
    "import skimage.exposure as ske\n",
    "import skimage.filters as skf\n",
    "\n",
    "def main(imgAnc, imgBnc, thrsA, runAlignment, onlyLgst, horizonBlur):\n",
    "    # this is the main function that takes the two original (color)\n",
    "    # images as input, and returns the final image combination\n",
    "    #\n",
    "    # image A is for the image you want to keep the darker portion of\n",
    "    # image B is for the image you want to keep the lighter portion of\n",
    "    # onlyLgst is a boolean to signal if only the largest connected component should be selected, \n",
    "    # or if every component above the given threshold ought to be used (imgA thrs. used only)\n",
    "    \n",
    "    if (imgAnc.shape != imgBnc.shape):\n",
    "        print(\"Please select two images of equal dimensions for input.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    if (runAlignment):\n",
    "        imgA, imgB = alignment(imgAnc, imgBnc)     # nc - not (yet) cropped original images\n",
    "    else:\n",
    "        imgA = imgAnc\n",
    "        imgB = imgBnc\n",
    "        \n",
    "    \n",
    "    res1, maskA = combine(imgA, imgB, thrsA, onlyLgst)\n",
    "    \n",
    "    \n",
    "    # now done creating our new image, except for blurring the horizon line a little bit\n",
    "    # so that the two disparate parts look a bit more cohesive...\n",
    "    \n",
    "    if (horizonBlur):\n",
    "        lineBlurred2, split2 = blurHorizon(res1, maskA)\n",
    "        # to join the two final pieces together and display\n",
    "        res2 = lineBlurred2 + split2\n",
    "    else:\n",
    "        res2 = res1 \n",
    "        \n",
    "    #resAlmostFinal = cv2.cvtColor(res2, cv2.COLOR_BGR2RGB)\n",
    "    resFinal = ske.rescale_intensity(res2)\n",
    "    \n",
    "    # modify these lines for the user interface\n",
    "    if (runAlignment):\n",
    "        resFinal = display(resFinal, False)     # because the runAlignment boolean has converted the colors to RGB already\n",
    "    else:\n",
    "        resFinal = display(resFinal, True)     # because the colors still need to be converted back to RGB\n",
    "    \n",
    "    cv2.imwrite(\"finalimg.jpg\", resFinal)\n",
    "\n",
    "def alignment(imgA, imgB):\n",
    "    # takes two images as input, aligns them, cropps the larger one to the size of the\n",
    "    # smaller one, then returns the two final images, image A and image B\n",
    "    \n",
    "    # color channels for image B\n",
    "    imgBRed = imgB[:,:,0]\n",
    "    imgBGreen = imgB[:,:,1]\n",
    "    imgBBlue = imgB[:,:,2]\n",
    "    \n",
    "    # color channels for image A\n",
    "    imgARed = imgA[:,:,0]\n",
    "    imgAGreen = imgA[:,:,1]\n",
    "    imgABlue = imgA[:,:,2]\n",
    "    \n",
    "    # convert images to grayscale (for correct sizing without color channels)\n",
    "    imgA_gray = cv2.cvtColor(imgA, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # find size of imgA; used when to ensure imgB will be same size as image 1 when aligned to it\n",
    "    size = imgA_gray.shape\n",
    "    \n",
    "    # define Affine motion model for alignment\n",
    "    align_mode = cv2.MOTION_AFFINE\n",
    "    # define and initialize 2x3 matrices\n",
    "    align_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "    \n",
    "    # specify the number of iterations\n",
    "    number_of_iterations = 1000\n",
    "    # specify the threshold of the increment in the correlation coefficient between two iterations\n",
    "    termination_eps = 1e-10;\n",
    "    # define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "    \n",
    "    # run the ECC algorithm for each color channel, results are stored in align_matrix.\n",
    "    (ccR, align_matrixR) = cv2.findTransformECC(imgA_gray,imgBRed,align_matrix, align_mode, criteria)\n",
    "    (ccG, align_matrixG) = cv2.findTransformECC(imgA_gray,imgBGreen,align_matrix, align_mode, criteria)\n",
    "    (ccB, align_matrixB) = cv2.findTransformECC(imgA_gray,imgBBlue,align_matrix, align_mode, criteria)\n",
    "    \n",
    "    # use warpAffine for Affine transformation\n",
    "    imgB_alignedRed = cv2.warpAffine(imgBRed, align_matrixR, (size[1],size[0]),\n",
    "                                         flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    imgB_alignedGreen = cv2.warpAffine(imgBGreen, align_matrixG, (size[1],size[0]),\n",
    "                                           flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    imgB_alignedBlue = cv2.warpAffine(imgBBlue, align_matrixB, (size[1],size[0]),\n",
    "                                          flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    \n",
    "    # final outputs\n",
    "    imgB_final = cv2.merge((imgB_alignedBlue, imgB_alignedGreen, imgB_alignedRed))\n",
    "    imgA_final = cv2.merge((imgABlue, imgAGreen, imgARed)) # necessary for showing \"real colors\" image\n",
    "    \n",
    "    cv2.imwrite(\"Final_Algined.jpg\", imgB_final)\n",
    "    imgB_final = cv2.imread(\"Final_Algined.jpg\")\n",
    "    \n",
    "    # and now to crop them, then return them\n",
    "    imgA_croppedFinal, imgB_croppedFinal = crop(imgA_final, imgB_final)\n",
    "    \n",
    "    return(imgA_croppedFinal, imgB_croppedFinal)\n",
    "\n",
    "def crop(imgA_final, imgB_final):\n",
    "    # cropping imgB (b) in reference to how it shifted\n",
    "    # cropping imgA (a) in reference to how imgB shifted\n",
    "    i = 0\n",
    "    j = 0\n",
    "    l = imgB_final.shape[0] - 1\n",
    "    m = imgB_final.shape[1] - 1\n",
    "    \n",
    "    \n",
    "    while ((imgB_final[i,j,0] == 0) & (imgB_final[i,j,1] == 0) & (imgB_final[i,j,2] == 0)):\n",
    "        i = i+25\n",
    "        j = j+25\n",
    "        \n",
    "    while ((imgB_final[l,m,0] == 0) & (imgB_final[l,m,1] == 0) & (imgB_final[l,m,2] == 0)):\n",
    "        l = l-25\n",
    "        m = m-25\n",
    "        \n",
    "        \n",
    "    final_imgA1 = imgA_final[:,j:m, ...]\n",
    "    cropped_imgA = final_imgA1[i:l,:, ...]\n",
    "    final_imgB1 = imgB_final[:,j:m, ...]\n",
    "    cropped_imgB = final_imgB1[i:l,:, ...]\n",
    "    \n",
    "    \n",
    "    return(cropped_imgA, cropped_imgB)\n",
    "\n",
    "def combine(imgA, imgB, thrsA, onlyLgst):\n",
    "    # takes the two initial images as input and returns the conjoined\n",
    "    # version without the horizon blur, along with maskA\n",
    "    \n",
    "    bwA = skc.rgb2gray(imgA)\n",
    "    bwB = skc.rgb2gray(imgB)\n",
    "    \n",
    "\n",
    "    # this series of connected componenets and inversions is meant to remove both\n",
    "    # extraneous black and white spots from each mask (maskA and maskB)\n",
    "    imgAThrs = bwA > thrsA\n",
    "    imgBThrs = ~imgAThrs     # B's thresholded image is solely dependent on what remains after A's\n",
    "    \n",
    "    if (onlyLgst):\n",
    "    \n",
    "        maskA1 = lgstComp(imgAThrs)\n",
    "        maskA2 = ~maskA1\n",
    "        maskA3 = lgstComp(maskA2)\n",
    "        maskA = ~maskA3\n",
    "    \n",
    "        maskB = maskA3\n",
    "        # mask B does not need to be inverted, because we want the foreground below mask A\n",
    "    \n",
    "    else:\n",
    "        maskA = imgAThrs\n",
    "        maskB = ~imgAThrs     # notice that image A's threshold is used in this case\n",
    "    \n",
    "\n",
    "    # alignment would happen here\n",
    "    \n",
    "    imgMskA = imgA.copy()\n",
    "    imgMskB = imgB.copy()\n",
    "\n",
    "    imgMskA[maskA] = 0\n",
    "    imgMskB[maskB] = 0    # already 'left inverted' above when thresholding\n",
    "    \n",
    "\n",
    "    #these three comment lines below can be deleted, it's just another way to merge the two pieces:\n",
    "    #masks1 = [imgMskA, imgMskB]\n",
    "    #mergeMertens1 = cv2.createMergeMertens()\n",
    "    #res1 = mergeMertens1.process(masks1)\n",
    "    \n",
    "    res1 = imgMskA | imgMskB\n",
    "\n",
    "    \n",
    "    return res1, maskA\n",
    "\n",
    "def lgstComp(imgT):\n",
    "    # returns the mask of the largest component (true) and the rest of the image (false)\n",
    "    \n",
    "    lblGero = skm.label(imgT, neighbors = 8)\n",
    "    compGero = skme.regionprops(lblGero)\n",
    "    \n",
    "    maxGero = 0\n",
    "    idxGero = None\n",
    "\n",
    "    for i in compGero:\n",
    "        if (i.area > maxGero):\n",
    "            maxGero = i.area\n",
    "            idxGero = i.label\n",
    "            \n",
    "    lbl = skm.label(imgT, neighbors = 8)\n",
    "    mask = (lbl == idxGero)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def blurHorizon(res1, maskA):\n",
    "    # takes as input maskA and res1 and returns the two partial\n",
    "    # images, to be comjoined within main() into the final image\n",
    "    \n",
    "    strel = skm.rectangle(5, 5)\n",
    "    \n",
    "    # now to manipulate the mask A until we have just the horizon line left\n",
    "    lineAdil = skm.dilation(maskA, selem = strel)\n",
    "    horizonMaskMessy = lineAdil ^ maskA     # because mask B was created from mask A anyway\n",
    "    horizonMask = lgstComp(horizonMaskMessy)\n",
    "    \n",
    "    #these three comment lines below can be deleted, it's just another way to merge the two pieces:\n",
    "    #lineAerr = skm.erosion(maskA, selem = strel)    # because mask B was created from mask A anyway\n",
    "    #horizonMaskMessyB = lineAerr ^ maskA\n",
    "    #horizonMaskMessy = horizonMaskMessyA | horizonMaskMessyB\n",
    "\n",
    "    \n",
    "    line = res1.copy()     # line will - eventually - have the masked horizon line only (with the median filter)\n",
    "    split = res1.copy()    # split will contain the rest of the image \"res1\" (without the median filter)\n",
    "    \n",
    "    lineBlurred = sknf.median_filter(line, footprint=np.ones((4, 4, 3)))\n",
    "    \n",
    "    lineBlurred[~horizonMask] = 0\n",
    "    split[horizonMask] = 0\n",
    "    \n",
    "    \n",
    "    # now to convert it to a uniform format so that both images line up\n",
    "    \n",
    "    split2 = ske.rescale_intensity(split)\n",
    "    lineBlurred2 = ske.rescale_intensity(lineBlurred)\n",
    "    \n",
    "    \n",
    "    return lineBlurred2, split2\n",
    "\n",
    "def display(img, toBeConverted):\n",
    "    # this is just for the diplay, and you're free to delete it\n",
    "    # if you display the images differently in the interface\n",
    "    \n",
    "    if (toBeConverted):\n",
    "        imgRet = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return imgRet\n",
    "        #plt.figure(figsize = (11, 10))\n",
    "        #skio.imshow(imgRet, cmap = 'gray')\n",
    "    else:\n",
    "        return img\n",
    "        #plt.figure(figsize = (11, 10))\n",
    "        #skio.imshow(img, cmap = 'gray')\n",
    "        \n",
    "class Window(Frame):\n",
    "    \n",
    "    def __init__(self, master = None):\n",
    "        Frame.__init__(self, master)\n",
    "        \n",
    "        self.master = master\n",
    "        \n",
    "        self.init_window()\n",
    "    \n",
    "    def init_window(self):\n",
    "        self.configure(background = \"black\")\n",
    "        \n",
    "        self.master.title(\"Exposure Splicing Project\")\n",
    "        \n",
    "        self.pack(fill = BOTH, expand = 1)\n",
    "        \n",
    "        menu = Menu(self.master)\n",
    "        self.master.config(menu = menu)\n",
    "        \n",
    "        file = Menu(menu)\n",
    "        file.add_command(label = 'Upload Image 1', command = self.upload1)\n",
    "        file.add_command(label = 'Upload Image 2', command = self.upload2)\n",
    "        menu.add_cascade(label = 'File', menu = file)\n",
    "        \n",
    "        self.slider1 = Scale(troughcolor = \"orange\", from_=0, to=1, resolution = 0.01, orient=\"horizontal\", label = \"Threshold\", bg = \"white\", length = 200, font=(\"Helvetica\", 16))\n",
    "        self.slider1.bind(\"<ButtonRelease-1>\", self.fix)\n",
    "        self.slider1.place(x = 450, y = 200)\n",
    "        \n",
    "        self.var1 = IntVar()\n",
    "        self.onlyLargest = Checkbutton(text=\"I want only the largest piece of image 1 above my chosen threshold.\", variable= self.var1, bg = \"black\", fg = \"white\", font=(\"Helvetica\", 16))\n",
    "        self.onlyLargest.place(x = 700, y = 205)\n",
    "        self.onlyLargest.v = self.var1\n",
    "        \n",
    "        self.var2 = BooleanVar()\n",
    "        self.blur = Checkbutton(text=\"I want to blur just a thin sliver of my final image along the intersection between the two original images.\", variable= self.var2, bg = \"black\", fg = \"white\", font=(\"Helvetica\", 16))\n",
    "        self.blur.place(x = 700, y = 230)\n",
    "        self.blur.v = self.var2\n",
    "        \n",
    "        self.var3 = BooleanVar()\n",
    "        self.align = Checkbutton(text=\"I want to align the imges first.\", variable= self.var3, bg = \"black\", fg = \"white\", font=(\"Helvetica\", 16))\n",
    "        self.align.place(x = 700, y = 180)\n",
    "        self.align.v = self.var3\n",
    "        \n",
    "        self.b = Checkbutton(variable=0, selectcolor = \"orange\", indicatoron=0, text=\"Fix\", background = \"black\", foreground= \"white\", font= (\"Helvetica\", 16))\n",
    "        self.b.bind(\"<ButtonRelease-1>\", self.fix)\n",
    "        self.b.deselect()\n",
    "        self.b.place(x = 700, y = 250)\n",
    "\n",
    "    def showImg1(self): \n",
    "        load = Image.open(\"firstimg.jpg\")\n",
    "        basewidth = 400\n",
    "        wpercent = (basewidth / float(load.size[0]))\n",
    "        hsize = int((float(load.size[1]) * float(wpercent)))\n",
    "        load = load.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "        render = ImageTk.PhotoImage(load)\n",
    "        img = Label(self, image = render)\n",
    "        img.image = render\n",
    "        img.place(x= 15, y = 200)\n",
    "\n",
    "    def upload1(self):\n",
    "        file = cv2.imread(filedialog.askopenfilename())\n",
    "        cv2.imwrite(\"firstimg.jpg\", file)\n",
    "        self.showImg1()\n",
    "    \n",
    "    def showImg2(self): \n",
    "        load = Image.open(\"secondimg.jpg\")\n",
    "        basewidth = 400\n",
    "        wpercent = (basewidth / float(load.size[0]))\n",
    "        hsize = int((float(load.size[1]) * float(wpercent)))\n",
    "        load = load.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "        render = ImageTk.PhotoImage(load)\n",
    "        img = Label(self, image = render)\n",
    "        img.image = render\n",
    "        img.place(x=1000, y=200)\n",
    "\n",
    "    def upload2(self):\n",
    "        file = cv2.imread(filedialog.askopenfilename())\n",
    "        cv2.imwrite(\"secondimg.jpg\", file)\n",
    "        self.showImg2()\n",
    "    \n",
    "    def showImg3(self): \n",
    "        load = Image.open(\"finalimg.jpg\")\n",
    "        basewidth = 550\n",
    "        wpercent = (basewidth / float(load.size[0]))\n",
    "        hsize = int((float(load.size[1]) * float(wpercent)))\n",
    "        load = load.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "        render = ImageTk.PhotoImage(load)\n",
    "        img = Label(self, image = render)\n",
    "        img.image = render\n",
    "        img.place(x=435, y=150)\n",
    "        \n",
    "    def fix(self, event):\n",
    "        self.b.deselect()\n",
    "        imgA = skio.imread(\"firstimg.jpg\")\n",
    "        imgB = skio.imread(\"secondimg.jpg\")\n",
    "        thrsA = self.slider1.get() \n",
    "        align = self.var3.get()\n",
    "        onlyLgst = self.var1.get()\n",
    "        blur = self.var2.get()\n",
    "        \n",
    "        main(imgA, imgB, thrsA, align, onlyLgst, blur)\n",
    "        \n",
    "        self.showImg3()\n",
    "\n",
    "root = Tk()\n",
    "root.geometry(\"1500x1000\")\n",
    "root.configure(background = \"black\")\n",
    "\n",
    "instruction1 = Label(text = \"Step 1: File - upload img 1\", font=(\"Helvetica\", 18, 'bold'), bg = \"black\", fg = \"white\")\n",
    "instruction1.pack(anchor = CENTER, pady = 10)\n",
    "\n",
    "instruction2 = Label(text = \"Step 2: File - upload img 2\",  font=(\"Helvetica\", 18, 'bold'), bg = \"black\", fg = \"white\")\n",
    "instruction2.pack(anchor = CENTER, pady= 5)\n",
    "\n",
    "instruction3 = Label(text = \"Step 3: Adjust threshold value\", font=(\"Helvetica\", 18, 'bold'), bg = \"black\", fg = \"white\")\n",
    "instruction3.pack(anchor = CENTER, pady = 5)\n",
    "\n",
    "instruction4 = Label(text = \"Step 4: Select desired checkboxes and click 'Fix'\", font=(\"Helvetica\", 18, 'bold'), bg = \"black\", fg = \"white\")\n",
    "instruction4.pack(anchor = CENTER, pady = 5)\n",
    "\n",
    "\n",
    "app = Window(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
